{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Xception \n",
    "\n",
    "### Xception: Deep Learning with Depthwise Separable Convolutions (Chollet F., 2016)\n",
    "\n",
    "*We present an interpretation of Inception modules in convolutional neural networks\n",
    "as being an intermediate step in __between regular convolution and the depthwise separable\n",
    "convolution operation__ (a depthwise convolution followed by a pointwise convolution)...*\n",
    "\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1610.02357v2?source=post_page---------------------------)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union, Tuple\n",
    "import pretrainedmodels\n",
    "\n",
    "assert torch.cuda.is_available() is True\n",
    "%load_ext watermark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%watermark -p torch,ignite,numpy,netron,pretrainedmodels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Depthwise separable convolution\n",
    "\n",
    "(Laurent Sifre at Google Brain in 2013, reported in V. Vanhoucke. Learning visual representations at scale. ICLR, 2014, PhD thesis Rigid-motion scattering for image classification, 2014)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The standard convolution extracts:\n",
    "* Spatial correlation across pixels within an image channel (spatial correlations)\n",
    "* Pixels correlation across channels (cross-channel correlations)\n",
    "\n",
    "This is actually what Inception block does! "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/2_xception.png\" width=\"450\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This simplified Inception block actually states that spatial and cross-channel correlations can be factorized.\n",
    "And the experiments showed it was true.\n",
    "\n",
    "Extreme case:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/3_xception.png\" width=\"450\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ideas is known as __depthwise separable convolution__. The only difference is the order of operations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/4_xception.jpeg\" width=\"490\">\n",
    "\n",
    "<img src=\"../assets/1_xception.png\" width=\"490\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Depthwise separable convolution from computational perspective:\n",
    "\n",
    "Let $F_{K \\times K \\times C} $ is the filter or kernel with dims $K \\times K \\times C$, $H_{G \\times G \\times N}$ is the resulting feature map with dims $G \\times G \\times N$ produced by a convolution with $N$ filters $F_{K \\times K \\times C}$ over $W \\times H \\times C$ input.\n",
    "\n",
    "Then:\n",
    "\n",
    "1) for the standard convolution the number of multiplications per kernel is:\n",
    "\n",
    "$$Mults_{1} = K^2 \\times C \\times G^2$$\n",
    "\n",
    "For N kernels:\n",
    "\n",
    "$$Mults_{N} = K^2 \\times C \\times G^2 \\times N$$\n",
    "\n",
    "2) for DWS convolution:\n",
    "\n",
    "* depthwise part:\n",
    "\n",
    "$$DW Mults = C \\times K^2 \\times G^2$$\n",
    "\n",
    "* pointwise part:\n",
    "\n",
    "$$PC Mults_{N} = N \\times G^2 \\times C$$\n",
    "\n",
    "$$DWSC_{Total} = C \\times K^2 \\times G^2 + N \\times G^2 \\times C = C \\times G^2 [K^2 + N]$$\n",
    "\n",
    "\n",
    "\n",
    "3) The reduction ratio:\n",
    "\n",
    "$$r = \\frac{C \\times G^2 [K^2 + N]}{K^2 \\times C \\times G^2 \\times N} = \\frac{1}{N} + \\frac{1}{K^2}$$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mults_reduction = lambda n, k: sum((1/n, 1/k**2))\n",
    "\n",
    "kernel_size = 3\n",
    "for n in range(32, 32+8*10, 8):\n",
    "    print('[n=%d]\\tconv has %.2f times more mults than DWS conv' % (n, 1/mults_reduction(n, kernel_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To make convolution work with each channel separately, __groups__ parameter is used: \n",
    "\n",
    "\n",
    "__Groups__ is a positive integer specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately with `filters / groups` filters. \n",
    "\n",
    "The output is the concatenation of all the groups results along the channel axis. Input channels and filters must both be divisible by groups. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Groups example:\n",
    "x = torch.Tensor(np.random.normal(size=(1, 25, 28, 28)))\n",
    "for g in (1, 5, 25):\n",
    "    conv = nn.Conv2d(in_channels=25, out_channels=50, kernel_size=3, padding=1, groups=g)\n",
    "    print(f'Group: {g} Weights: {conv.weight.shape} Output: {conv(x).shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DWSConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Depthwise separable convolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Union[int, Tuple[int, int]],\n",
    "                 kernels_per_layer: int,\n",
    "                 stride: Union[int, Tuple[int, int]] = 1,\n",
    "                 padding: Union[str, int, Tuple[int, int]] = 0,\n",
    "                 dilation: Union[int, Tuple[int, int]] = 1,\n",
    "                 groups: int = 1,\n",
    "                 *kwargs):\n",
    "        super(DWSConv2d, self).__init__(*kwargs)\n",
    "\n",
    "        self.dw_conv2d = nn.Conv2d(in_channels, in_channels * kernels_per_layer,\n",
    "                                   kernel_size=kernel_size, padding=padding,\n",
    "                                   groups=in_channels)\n",
    "        self.pw_conv2d = nn.Conv2d(in_channels * kernels_per_layer, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.pw_conv2d(self.dw_conv2d(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Xception (Extreme Inception) components:\n",
    "   * InceptionV3 blocks -> DWSConv blocks\n",
    "   * Residual connections\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/5_xception.png\" width=\"800\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/6_xception.png\" width=\"530\">\n",
    "\n",
    "<img src=\"../assets/7_xception.png\" width=\"700\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Torch [implementation](https://github.com/Cadene/pretrained-models.pytorch/blob/8aae3d8f1135b6b13fed79c1d431e3449fdbf6e0/pretrainedmodels/models/xception.py#L114)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xception = pretrainedmodels.xception(pretrained=False)\n",
    "xception"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Your training code here"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define data transformation pipeline.\n",
    "\n",
    "\n",
    "# Initialize dataset and dataloaders.\n",
    "\n",
    "\n",
    "# Initialize pretrained network, replace Linear layer with a new one for your dataset.\n",
    "\n",
    "\n",
    "# Initialize optimizer, loss function and training procedure with handlers/callbacks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### References\n",
    "\n",
    "* https://github.com/Cadene/pretrained-models.pytorch#xception\n",
    "* https://onnx.ai/\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* https://pytorch.org/docs/0.3.1/nn.html#torch.nn.Conv2d\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "* https://www.researchgate.net/publication/343943234_Real-Time_Food_Intake_Monitoring_Using_Wearable_Egocnetric_Camera"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}