{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### VGG \n",
    "\n",
    "### Very Deep Convolutional Networks for Large-Scale Image Recognition (Simonyan K. , ZissermanA. , 2014)\n",
    "[Paper](https://arxiv.org/abs/1409.1556v6)\n",
    "\n",
    "\n",
    "*In this work we __investigate the effect of the convolutional network depth on its\n",
    "accuracy__ in the large-scale image recognition setting. Our __main contribution is\n",
    "a thorough evaluation of networks of increasing depth using an architecture with\n",
    "very small (3 × 3) convolution filters__, which shows that a significant improvement\n",
    "on the prior-art configurations can be achieved by pushing __the depth to 16–19\n",
    "weight layers__. These findings were the basis of our __ImageNet Challenge 2014__\n",
    "submission, where our team secured __the first and the second places in the localisa-\n",
    "tion and classification tracks__ respectively.*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Fbeta, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert torch.cuda.is_available() is True\n",
    "%load_ext watermark"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%watermark -p torch,ignite,numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### VGG topology\n",
    "![VGGTOP](../assets/3_vgg_conf.jpg)\n",
    "<img src=\"../assets/5_vgg_params.png\" width=\"400\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### VGG-16\n",
    "![VGG16_1](../assets/1_vgg16.jpg)\n",
    "![VGG16_2](../assets/2_vgg16.jpg)\n",
    "![VGG16_4](../assets/4_vgg_perf.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convolutional kernels 1x1 in VGG, type C\n",
    "\n",
    "* 1x1 without reducing feature maps depth!\n",
    "\n",
    "*The incorporation of 1 × 1 conv. layers is a __way to increase the non-\n",
    "linearity of the decision function without affecting the receptive fields of the conv. layers__. Even\n",
    "though in our case the 1 × 1 convolution is essentially a __linear projection onto the space of the same\n",
    "dimensionality__ (the number of input and output channels is the same), an __additional non-linearity__ is\n",
    "introduced by the rectification function.*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../assets/6_vgg_article_perf.png\" width=\"600\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Torch [implementation](https://github.com/pytorch/vision/blob/7d868aa608b94d022c42357ede40bda06af942f4/torchvision/models/vgg.py#L35)\n",
    "\n",
    "```python\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's new:\n",
    "\n",
    "* AdaptiveAvgPool2d with output_size as the only argument instead of MaxPool with kernel_size\n",
    "* A, B, D, E configurations: 3x3 convolutional kernels\n",
    "* Optional BatchNorm layers [(Sergey I. Szegedy C., 2015)](https://arxiv.org/abs/1502.03167)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sequential blocks: feature extractor -> pooling -> classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuple(arch for arch in dir(torchvision.models) if 'vgg'in arch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg11_bn = torchvision.models.vgg11_bn(pretrained=True, progress=False)\n",
    "vgg11_bn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CIFAR10 with pytorch ignite"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imagenet_norm = {'mean':(0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225)}\n",
    "val_start = 45000\n",
    "batch_size = 64\n",
    "store_data = './data'\n",
    "device = 'cuda:0'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(**imagenet_norm)])\n",
    "\n",
    "trainset = datasets.CIFAR10(store_data, download=True, train=True, transform=transform)\n",
    "trainset.targets = trainset.targets[:val_start]\n",
    "trainset.data = trainset.data[:val_start]\n",
    "\n",
    "valset = datasets.CIFAR10(store_data, download=False, train=True, transform=transform)\n",
    "valset.targets = valset.targets[val_start:]\n",
    "valset.data = valset.data[val_start:]\n",
    "\n",
    "testset = datasets.CIFAR10(store_data, download=True, train=False, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_imgs = 5\n",
    "fig, axs = plt.subplots(1, n_imgs)\n",
    "for i, idx in enumerate(np.random.randint(size=n_imgs, low=0, high=trainset.data.shape[0]-1)):\n",
    "    axs[i].imshow(trainset.data[idx])\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title(trainset.classes[trainset.targets[idx]])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(len(trainset.targets), len(valset.targets), len(testset.targets))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(trainset.data.shape, valset.data.shape, testset.data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainset.classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg11_bn.classifier[-1] = nn.Linear(in_features=4096, out_features=len(trainset.classes))\n",
    "vgg11_bn.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.Adam(vgg11_bn.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "vgg11_bn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "trainer = create_supervised_trainer(vgg11_bn, optimizer, criterion, device=device)\n",
    "metrics = {\n",
    "    'f1': Fbeta(beta=1),\n",
    "    'ce':Loss(criterion),\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(vgg11_bn, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(vgg11_bn, metrics=metrics, device=device)\n",
    "\n",
    "training_history = {'loss':[], 'f1': []}\n",
    "validation_history = {'loss':[], 'f1': []}\n",
    "last_epoch = []\n",
    "\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Available events: {dir(Events)[:-4]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    f1 = metrics['f1']\n",
    "    loss = metrics['ce']\n",
    "    last_epoch.append(0)\n",
    "    training_history['f1'].append(f1)\n",
    "    training_history['loss'].append(loss)\n",
    "    print(\"Training Results - Epoch: {}  Avg F1: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, f1, loss))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    f1 = metrics['f1']\n",
    "    loss = metrics['ce']\n",
    "    validation_history['f1'].append(f1)\n",
    "    validation_history['loss'].append(loss)\n",
    "    print(\"Validation Results - Epoch: {}  Avg F1: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, f1, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_last_val_score = lambda x: validation_history['f1'][-1]\n",
    "get_last_epoch = lambda eng, last_state: eng.state.epoch\n",
    "checkpointer = ModelCheckpoint('./saved_models', 'vgg11bn', \n",
    "                               global_step_transform=get_last_epoch,\n",
    "                               score_function=get_last_val_score,\n",
    "                               create_dir=True, \n",
    "                               require_empty=False)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'cifar10': vgg11_bn})\n",
    "\n",
    "ignite_pbar = ProgressBar()\n",
    "ignite_pbar.attach(trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_last_checkpoint(model_save_path, name):\n",
    "    checkpoint_files = (x for x in os.listdir(model_save_path) if name in x)\n",
    "    checkpoint_files = [f for f in checkpoint_files if '.pt' in f]\n",
    "    checkpoint_iter = [\n",
    "        int(x.split('_')[2].split('.')[0])\n",
    "        for x in checkpoint_files]\n",
    "    last_idx = np.array(checkpoint_iter).argmax()\n",
    "    return os.path.join(model_save_path, checkpoint_files[last_idx])\n",
    "\n",
    "vgg11_bn.load_state_dict(torch.load(fetch_last_checkpoint('./saved_models', 'vgg11bn_cifar10')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_evaluator = create_supervised_evaluator(vgg11_bn, metrics=metrics, device=device)\n",
    "vgg11_bn.eval()\n",
    "ProgressBar().attach(test_evaluator)\n",
    "test_evaluator.run(test_loader)\n",
    "test_evaluator.state.metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### References\n",
    "\n",
    "* http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf\n",
    "* https://www.geeksforgeeks.org/vgg-16-cnn-model/\n",
    "* https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/FashionMNIST.ipynb#scrollTo=Pj7oLY36abx8\n",
    "* https://pytorch.org/\n",
    "* https://pytorch.org/ignite/\n",
    "* https://onnx.ai/\n",
    "* https://www.cs.toronto.edu/~kriz/cifar.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}