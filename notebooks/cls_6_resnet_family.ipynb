{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1533390a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wide ResNet & ResNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f37ca85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import netron\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "assert torch.cuda.is_available() is True\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f28c6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch  : 1.10.2\n",
      "ignite : 0.4.8\n",
      "numpy  : 1.22.1\n",
      "netron : 5.5.5\n",
      "sklearn: 0.24.2\n",
      "pandas : 1.4.1\n",
      "plotly : 5.6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -p torch,ignite,numpy,netron,sklearn,pandas,plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46389d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Wide ResNet, Wide Residual Networks (Zagoruyko S., 2016)\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1605.07146)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60a731f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* *The residual block with identity mapping that allows to train very deep networks is at the same time a weakness of residual networks. As gradient flows through the network there is nothing to force it to go through residual block weights and it can avoid learning anything during training, so it is possible that there is either only a few blocks that learn useful representations, or many blocks share very little information with small contribution to the final goal.*\n",
    "\n",
    "\n",
    "* Two factors: \n",
    "    * deepening factor $l$ is the number of convolutions in a block, \n",
    "    * widening factor $k$ multiplies the number of features in convolutional layers. The baseline «basic» block: $l$ = 2, $k$ = 1. \n",
    "   \n",
    "   \n",
    "* $B(M)$ is the residual block structure with list $M$ of conv kernel sizes. so\n",
    "\n",
    "    1. $B(3, 3)$ - original «basic» block;\n",
    "    2. $B(3, 1, 3)$ - with one extra 1 × 1 layer;\n",
    "    3. $B(1, 3, 1)$ - with the same dimensionality of all convolutions, «straightened» bottleneck;\n",
    "    4. $B(1, 3)$ - the network has alternating 1 × 1 - 3 × 3 convolutions everywhere;\n",
    "    5. $B(3, 1)$ - similar idea to the previous block;\n",
    "    6. $B(3, 1, 1)$ - Network-in-Network style block;\n",
    "\n",
    "\n",
    "* It is more computationally effective to widen the layers than have thousands of small kernels as GPU is much more efficient in parallel computations on large tensors, so we are interested in an optimal $\\frac{d}{k}$ ratio.\n",
    "\n",
    "\n",
    "* The widening of ResNet blocks (if done properly) provides a much more effective way of improving performance of residual networks compared to increasing their depth.\n",
    "\n",
    "\n",
    "* __WRN-n-k__ denotes a residual network that has a total number of convolutional layers $n$ and a widening factor $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce800899",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"../assets/1_wide_resnet.png\" width=\"600\">\n",
    "\n",
    "<img src=\"../assets/2_wide_resnet.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f85987a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"../assets/3_wide_resnet.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82694f0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Torch [implementation](https://github.com/pytorch/vision/blob/b4cb352c586ee6104a79b2d367d019ca480759b3/torchvision/models/resnet.py#L382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1f973e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wide_resnet101_2', 'wide_resnet50_2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(arch for arch in dir(torchvision.models) if re.match('wide', arch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e35287",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ResNext, Aggregated Residual Transformations for Deep Neural Networks (Xie S. et al., Facebook AI Research, 2017)\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1611.05431)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada4720",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "* Homogeneous, multi-branch architecture that has only a few hyper-parameters to set;\n",
    "\n",
    "\n",
    "* New “cardinality” dimension $C$ (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width;\n",
    "\n",
    "\n",
    "* Group convolutions as equivalent to the multiple branches in a ResNeXt block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b3cb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"../assets/1_resnext.png\" width=\"500\">\n",
    "\n",
    "<img src=\"../assets/2_resnext.png\" width=\"450\">\n",
    "\n",
    "<img src=\"../assets/3_resnext.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c3c21",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* resnext50_32x4d 32 groups, 4d channels per group;\n",
    "    * conv2, d=1, 4 channels per group;\n",
    "    * conv3, d=2, 8 channels per group;\n",
    "    * conv4, d=4, 16 channels per group;\n",
    "    * conv5, d=8, 32 channels per group;\n",
    "* resnext101_32x8d: 32 groups, 8d channels per group;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f0e208",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Torch [implementation](https://github.com/pytorch/vision/blob/b4cb352c586ee6104a79b2d367d019ca480759b3/torchvision/models/resnet.py#L356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9bfe5c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('resnext101_32x8d', 'resnext50_32x4d')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(arch for arch in dir(torchvision.models) if re.match('resnext', arch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f825e621",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'onnx_graphs/mbnet2.onnx' at http://localhost:30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 30000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnext50 = torchvision.models.resnext50_32x4d()\n",
    "x = torch.Tensor(np.random.normal(size=(1, 3, 224, 224)))\n",
    "model_path = os.path.join('onnx_graphs', 'mbnet2.onnx')\n",
    "torch.onnx.export(resnext50, x, model_path,\n",
    "                  input_names=['input'], output_names=['output'], opset_version=10)\n",
    "netron.start(model_path, 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584fb1d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Your training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb790e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define data transformation pipeline.\n",
    "\n",
    "\n",
    "# Initialize dataset and dataloaders.\n",
    "\n",
    "\n",
    "# Initialize pretrained network, replace Linear layer with a new one for your dataset.\n",
    "\n",
    "\n",
    "# Initialize optimizer, loss function and training procedure with handlers/callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cf6ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### References\n",
    "\n",
    "* https://github.com/szagoruyko/wide-residual-networks\n",
    "* https://pytorch.org/hub/pytorch_vision_wide_resnet/\n",
    "* https://github.com/facebookresearch/ResNeXt\n",
    "* https://pytorch.org/hub/pytorch_vision_resnext/\n",
    "* https://onnx.ai/\n",
    "* https://pytorch.org/docs/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
